{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/usr/local/spark')\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('BigDataTask').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.2.15:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.2.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>BigDataTask</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fcfa651ec88>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Customer_id: integer (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- Region_Code: string (nullable = true)\n",
      " |-- State_Code: string (nullable = true)\n",
      " |-- City_Code: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bank_details = spark.read.load(\"Customer_and_bank details_p1.csv\", format=\"csv\", inferSchema=\"true\", header=\"true\")\n",
    "bank_details.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---+-----------+--------+-------------------+-------+-------+----+-----------+----------+---------+\n",
      "|Customer_id|age|        job| marital|          education|default|housing|loan|Region_Code|State_Code|City_Code|\n",
      "+-----------+---+-----------+--------+-------------------+-------+-------+----+-----------+----------+---------+\n",
      "|          1| 56|   services| married|        high.school|     no|     no| yes|          3|        S1|       C1|\n",
      "|          2| 45|   services| married|           basic.9y|unknown|     no|  no|          3|        S1|       C1|\n",
      "|          3| 59|     admin.| married|professional.course|     no|     no|  no|          4|        S2|       C2|\n",
      "|          4| 41|blue-collar| married|            unknown|unknown|     no|  no|          3|        S3|       C3|\n",
      "|          5| 24| technician|  single|professional.course|     no|    yes|  no|          3|        S3|       C3|\n",
      "|          6| 25|   services|  single|        high.school|     no|    yes|  no|          4|        S2|       C2|\n",
      "|          7| 41|blue-collar| married|            unknown|unknown|     no|  no|          4|        S2|       C2|\n",
      "|          8| 25|   services|  single|        high.school|     no|    yes|  no|          4|        S2|       C2|\n",
      "|          9| 29|blue-collar|  single|        high.school|     no|     no| yes|          4|        S2|       C2|\n",
      "|         10| 57|  housemaid|divorced|           basic.4y|     no|    yes|  no|         Na|        S2|       C2|\n",
      "+-----------+---+-----------+--------+-------------------+-------+-------+----+-----------+----------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bank_details.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Customer_id: integer (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- day_of_week: string (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- campaign: integer (nullable = true)\n",
      " |-- pdays: integer (nullable = true)\n",
      " |-- previous: integer (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "campaign_details = spark.read.load(\"Customer_campaign_details_p1.csv\", format=\"csv\", inferSchema=\"true\", header=\"true\")\n",
    "campaign_details.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+-----+-----------+--------+--------+-----+--------+-----------+\n",
      "|Customer_id|  contact|month|day_of_week|duration|campaign|pdays|previous|   poutcome|\n",
      "+-----------+---------+-----+-----------+--------+--------+-----+--------+-----------+\n",
      "|          1|telephone|  may|        mon|     307|       1|  999|       0|nonexistent|\n",
      "|          2|telephone|  may|        mon|     198|       1|  999|       0|nonexistent|\n",
      "|          3|telephone|  may|        mon|     139|       1|  999|       0|nonexistent|\n",
      "|          4|telephone|  may|        mon|     217|       1|  999|       0|nonexistent|\n",
      "|          5|telephone|  may|        mon|     380|       1|  999|       0|nonexistent|\n",
      "|          6|telephone|  may|        mon|      50|       1|  999|       0|nonexistent|\n",
      "|          7|telephone|  may|        mon|      55|       1|  999|       0|nonexistent|\n",
      "|          8|telephone|  may|        mon|     222|       1|  999|       0|nonexistent|\n",
      "|          9|telephone|  may|        mon|     137|       1|  999|       0|nonexistent|\n",
      "|         10|telephone|  may|        mon|     293|       1|  999|       0|nonexistent|\n",
      "+-----------+---------+-----+-----------+--------+--------+-----+--------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "campaign_details.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Customer_id: integer (nullable = true)\n",
      " |-- y: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response_data = spark.read.load(\"Customer_Response_data_p1.csv\", format=\"csv\", inferSchema=\"true\", header=\"true\")\n",
    "response_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---+\n",
      "|Customer_id|  y|\n",
      "+-----------+---+\n",
      "|          1| no|\n",
      "|          2| no|\n",
      "|          3| no|\n",
      "|          4| no|\n",
      "|          5| no|\n",
      "|          6| no|\n",
      "|          7| no|\n",
      "|          8| no|\n",
      "|          9| no|\n",
      "|         10| no|\n",
      "+-----------+---+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response_data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Customer_id: integer (nullable = true)\n",
      " |-- emp.var.rate: double (nullable = true)\n",
      " |-- cons.price.idx: double (nullable = true)\n",
      " |-- cons.conf.idx: double (nullable = true)\n",
      " |-- euribor3m: double (nullable = true)\n",
      " |-- nr.employed: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "economic_data=spark.read.load(\"Customer_social_economic_data_p1.csv\", format=\"csv\", inferSchema=\"true\", header=\"true\")\n",
    "economic_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+--------------+-------------+---------+-----------+\n",
      "|Customer_id|emp.var.rate|cons.price.idx|cons.conf.idx|euribor3m|nr.employed|\n",
      "+-----------+------------+--------------+-------------+---------+-----------+\n",
      "|          1|         1.1|        93.994|        -36.4|    4.857|     5191.0|\n",
      "|          2|         1.1|        93.994|        -36.4|    4.857|     5191.0|\n",
      "|          3|         1.1|        93.994|        -36.4|    4.857|     5191.0|\n",
      "|          4|         1.1|        93.994|        -36.4|    4.857|     5191.0|\n",
      "|          5|         1.1|        93.994|        -36.4|    4.857|     5191.0|\n",
      "|          6|         1.1|        93.994|        -36.4|    4.857|     5191.0|\n",
      "|          7|         1.1|        93.994|        -36.4|    4.857|     5191.0|\n",
      "|          8|         1.1|        93.994|        -36.4|    4.857|     5191.0|\n",
      "|          9|         1.1|        93.994|        -36.4|    4.857|     5191.0|\n",
      "|         10|         1.1|        93.994|        -36.4|    4.857|     5191.0|\n",
      "+-----------+------------+--------------+-------------+---------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "economic_data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Customer_id: integer (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- Region_Code: string (nullable = true)\n",
      " |-- State_Code: string (nullable = true)\n",
      " |-- City_Code: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- day_of_week: string (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- campaign: integer (nullable = true)\n",
      " |-- pdays: integer (nullable = true)\n",
      " |-- previous: integer (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer_details =bank_details.join(campaign_details, on='Customer_id')\n",
    "customer_details.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---+-----------+--------+-------------------+-------+-------+----+-----------+----------+---------+---------+-----+-----------+--------+--------+-----+--------+-----------+\n",
      "|Customer_id|age|        job| marital|          education|default|housing|loan|Region_Code|State_Code|City_Code|  contact|month|day_of_week|duration|campaign|pdays|previous|   poutcome|\n",
      "+-----------+---+-----------+--------+-------------------+-------+-------+----+-----------+----------+---------+---------+-----+-----------+--------+--------+-----+--------+-----------+\n",
      "|          1| 56|   services| married|        high.school|     no|     no| yes|          3|        S1|       C1|telephone|  may|        mon|     307|       1|  999|       0|nonexistent|\n",
      "|          2| 45|   services| married|           basic.9y|unknown|     no|  no|          3|        S1|       C1|telephone|  may|        mon|     198|       1|  999|       0|nonexistent|\n",
      "|          3| 59|     admin.| married|professional.course|     no|     no|  no|          4|        S2|       C2|telephone|  may|        mon|     139|       1|  999|       0|nonexistent|\n",
      "|          4| 41|blue-collar| married|            unknown|unknown|     no|  no|          3|        S3|       C3|telephone|  may|        mon|     217|       1|  999|       0|nonexistent|\n",
      "|          5| 24| technician|  single|professional.course|     no|    yes|  no|          3|        S3|       C3|telephone|  may|        mon|     380|       1|  999|       0|nonexistent|\n",
      "|          6| 25|   services|  single|        high.school|     no|    yes|  no|          4|        S2|       C2|telephone|  may|        mon|      50|       1|  999|       0|nonexistent|\n",
      "|          7| 41|blue-collar| married|            unknown|unknown|     no|  no|          4|        S2|       C2|telephone|  may|        mon|      55|       1|  999|       0|nonexistent|\n",
      "|          8| 25|   services|  single|        high.school|     no|    yes|  no|          4|        S2|       C2|telephone|  may|        mon|     222|       1|  999|       0|nonexistent|\n",
      "|          9| 29|blue-collar|  single|        high.school|     no|     no| yes|          4|        S2|       C2|telephone|  may|        mon|     137|       1|  999|       0|nonexistent|\n",
      "|         10| 57|  housemaid|divorced|           basic.4y|     no|    yes|  no|         Na|        S2|       C2|telephone|  may|        mon|     293|       1|  999|       0|nonexistent|\n",
      "+-----------+---+-----------+--------+-------------------+-------+-------+----+-----------+----------+---------+---------+-----+-----------+--------+--------+-----+--------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer_details.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Customer_id: integer (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- Region_Code: string (nullable = true)\n",
      " |-- State_Code: string (nullable = true)\n",
      " |-- City_Code: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- day_of_week: string (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- campaign: integer (nullable = true)\n",
      " |-- pdays: integer (nullable = true)\n",
      " |-- previous: integer (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- y: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df=customer_details.join(response_data, on='Customer_id')\n",
    "final_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---+-----------+--------+-------------------+-------+-------+----+-----------+----------+---------+---------+-----+-----------+--------+--------+-----+--------+-----------+---+\n",
      "|Customer_id|age|        job| marital|          education|default|housing|loan|Region_Code|State_Code|City_Code|  contact|month|day_of_week|duration|campaign|pdays|previous|   poutcome|  y|\n",
      "+-----------+---+-----------+--------+-------------------+-------+-------+----+-----------+----------+---------+---------+-----+-----------+--------+--------+-----+--------+-----------+---+\n",
      "|          1| 56|   services| married|        high.school|     no|     no| yes|          3|        S1|       C1|telephone|  may|        mon|     307|       1|  999|       0|nonexistent| no|\n",
      "|          2| 45|   services| married|           basic.9y|unknown|     no|  no|          3|        S1|       C1|telephone|  may|        mon|     198|       1|  999|       0|nonexistent| no|\n",
      "|          3| 59|     admin.| married|professional.course|     no|     no|  no|          4|        S2|       C2|telephone|  may|        mon|     139|       1|  999|       0|nonexistent| no|\n",
      "|          4| 41|blue-collar| married|            unknown|unknown|     no|  no|          3|        S3|       C3|telephone|  may|        mon|     217|       1|  999|       0|nonexistent| no|\n",
      "|          5| 24| technician|  single|professional.course|     no|    yes|  no|          3|        S3|       C3|telephone|  may|        mon|     380|       1|  999|       0|nonexistent| no|\n",
      "|          6| 25|   services|  single|        high.school|     no|    yes|  no|          4|        S2|       C2|telephone|  may|        mon|      50|       1|  999|       0|nonexistent| no|\n",
      "|          7| 41|blue-collar| married|            unknown|unknown|     no|  no|          4|        S2|       C2|telephone|  may|        mon|      55|       1|  999|       0|nonexistent| no|\n",
      "|          8| 25|   services|  single|        high.school|     no|    yes|  no|          4|        S2|       C2|telephone|  may|        mon|     222|       1|  999|       0|nonexistent| no|\n",
      "|          9| 29|blue-collar|  single|        high.school|     no|     no| yes|          4|        S2|       C2|telephone|  may|        mon|     137|       1|  999|       0|nonexistent| no|\n",
      "|         10| 57|  housemaid|divorced|           basic.4y|     no|    yes|  no|         Na|        S2|       C2|telephone|  may|        mon|     293|       1|  999|       0|nonexistent| no|\n",
      "+-----------+---+-----------+--------+-------------------+-------+-------+----+-----------+----------+---------+---------+-----+-----------+--------+--------+-----+--------+-----------+---+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_df=final_df.withColumnRenamed(\"y\",\"Deposit\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Customer_id: integer (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- Region_Code: string (nullable = true)\n",
      " |-- State_Code: string (nullable = true)\n",
      " |-- City_Code: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- day_of_week: string (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- campaign: integer (nullable = true)\n",
      " |-- pdays: integer (nullable = true)\n",
      " |-- previous: integer (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- Deposit: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37084"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Customer_id: integer (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- day_of_week: string (nullable = true)\n",
      " |-- campaign: integer (nullable = true)\n",
      " |-- pdays: integer (nullable = true)\n",
      " |-- previous: integer (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- Deposit: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list=['Region_Code','State_Code','City_Code','duration']\n",
    "customer_final = final_df.drop(*list)\n",
    "customer_final.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- Region_Code: string (nullable = true)\n",
      " |-- State_Code: string (nullable = true)\n",
      " |-- City_Code: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- day_of_week: string (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- campaign: integer (nullable = true)\n",
      " |-- pdays: integer (nullable = true)\n",
      " |-- previous: integer (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- Deposit: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer_final = final_df.drop('Customer_id')\n",
    "customer_final.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+--------+-------------------+-------+-------+----+-----------+----------+---------+---------+-----+-----------+--------+--------+-----+--------+-----------+-------+\n",
      "|age|        job| marital|          education|default|housing|loan|Region_Code|State_Code|City_Code|  contact|month|day_of_week|duration|campaign|pdays|previous|   poutcome|Deposit|\n",
      "+---+-----------+--------+-------------------+-------+-------+----+-----------+----------+---------+---------+-----+-----------+--------+--------+-----+--------+-----------+-------+\n",
      "| 56|   services| married|        high.school|     no|     no| yes|          3|        S1|       C1|telephone|  may|        mon|     307|       1|  999|       0|nonexistent|     no|\n",
      "| 45|   services| married|           basic.9y|unknown|     no|  no|          3|        S1|       C1|telephone|  may|        mon|     198|       1|  999|       0|nonexistent|     no|\n",
      "| 59|     admin.| married|professional.course|     no|     no|  no|          4|        S2|       C2|telephone|  may|        mon|     139|       1|  999|       0|nonexistent|     no|\n",
      "| 41|blue-collar| married|            unknown|unknown|     no|  no|          3|        S3|       C3|telephone|  may|        mon|     217|       1|  999|       0|nonexistent|     no|\n",
      "| 24| technician|  single|professional.course|     no|    yes|  no|          3|        S3|       C3|telephone|  may|        mon|     380|       1|  999|       0|nonexistent|     no|\n",
      "| 25|   services|  single|        high.school|     no|    yes|  no|          4|        S2|       C2|telephone|  may|        mon|      50|       1|  999|       0|nonexistent|     no|\n",
      "| 41|blue-collar| married|            unknown|unknown|     no|  no|          4|        S2|       C2|telephone|  may|        mon|      55|       1|  999|       0|nonexistent|     no|\n",
      "| 25|   services|  single|        high.school|     no|    yes|  no|          4|        S2|       C2|telephone|  may|        mon|     222|       1|  999|       0|nonexistent|     no|\n",
      "| 29|blue-collar|  single|        high.school|     no|     no| yes|          4|        S2|       C2|telephone|  may|        mon|     137|       1|  999|       0|nonexistent|     no|\n",
      "| 57|  housemaid|divorced|           basic.4y|     no|    yes|  no|         Na|        S2|       C2|telephone|  may|        mon|     293|       1|  999|       0|nonexistent|     no|\n",
      "+---+-----------+--------+-------------------+-------+-------+----+-----------+----------+---------+---------+-----+-----------+--------+--------+-----+--------+-----------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer_final.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---+-----------+--------+-------------------+-------+-------+----+-----------+----------+---------+\n",
      "|Customer_id|age|        job| marital|          education|default|housing|loan|Region_Code|State_Code|City_Code|\n",
      "+-----------+---+-----------+--------+-------------------+-------+-------+----+-----------+----------+---------+\n",
      "|          1| 56|   services| married|        high.school|     no|     no| yes|          3|        S1|       C1|\n",
      "|          2| 45|   services| married|           basic.9y|unknown|     no|  no|          3|        S1|       C1|\n",
      "|          3| 59|     admin.| married|professional.course|     no|     no|  no|          4|        S2|       C2|\n",
      "|          4| 41|blue-collar| married|            unknown|unknown|     no|  no|          3|        S3|       C3|\n",
      "|          5| 24| technician|  single|professional.course|     no|    yes|  no|          3|        S3|       C3|\n",
      "|          6| 25|   services|  single|        high.school|     no|    yes|  no|          4|        S2|       C2|\n",
      "|          7| 41|blue-collar| married|            unknown|unknown|     no|  no|          4|        S2|       C2|\n",
      "|          8| 25|   services|  single|        high.school|     no|    yes|  no|          4|        S2|       C2|\n",
      "|          9| 29|blue-collar|  single|        high.school|     no|     no| yes|          4|        S2|       C2|\n",
      "|         10| 57|  housemaid|divorced|           basic.4y|     no|    yes|  no|         Na|        S2|       C2|\n",
      "|         11| 35|blue-collar| married|           basic.6y|     no|    yes|  no|          4|        S2|       C2|\n",
      "|         12| 54|    retired| married|           basic.9y|unknown|    yes| yes|          4|        S2|       C2|\n",
      "|         13| 35|blue-collar| married|           basic.6y|     no|    yes|  no|          3|        S4|       C4|\n",
      "|         14| 46|blue-collar| married|           basic.6y|unknown|    yes| yes|          4|        S5|       C5|\n",
      "|         15| 50|blue-collar| married|           basic.9y|     no|    yes| yes|          1|        S6|       C6|\n",
      "|         16| 39| management|  single|           basic.9y|unknown|     no|  no|          1|        S6|       C6|\n",
      "|         17| 55|blue-collar| married|           basic.4y|unknown|    yes|  no|          1|        S7|       C7|\n",
      "|         18| 55|    retired|  single|        high.school|     no|    yes|  no|          4|        S8|       C8|\n",
      "|         19| 41| technician|  single|        high.school|     no|    yes|  no|          4|        S2|       C9|\n",
      "|         20| 37|     admin.| married|        high.school|     no|    yes|  no|          4|        S2|       C9|\n",
      "+-----------+---+-----------+--------+-------------------+-------+-------+----+-----------+----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bank_details.write.mode(\"overwrite\").saveAsTable('bank_details')\n",
    "spark.sql(\"select * from bank_details\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+-----+-----------+--------+--------+-----+--------+-----------+\n",
      "|Customer_id|  contact|month|day_of_week|duration|campaign|pdays|previous|   poutcome|\n",
      "+-----------+---------+-----+-----------+--------+--------+-----+--------+-----------+\n",
      "|          1|telephone|  may|        mon|     307|       1|  999|       0|nonexistent|\n",
      "|          2|telephone|  may|        mon|     198|       1|  999|       0|nonexistent|\n",
      "|          3|telephone|  may|        mon|     139|       1|  999|       0|nonexistent|\n",
      "|          4|telephone|  may|        mon|     217|       1|  999|       0|nonexistent|\n",
      "|          5|telephone|  may|        mon|     380|       1|  999|       0|nonexistent|\n",
      "|          6|telephone|  may|        mon|      50|       1|  999|       0|nonexistent|\n",
      "|          7|telephone|  may|        mon|      55|       1|  999|       0|nonexistent|\n",
      "|          8|telephone|  may|        mon|     222|       1|  999|       0|nonexistent|\n",
      "|          9|telephone|  may|        mon|     137|       1|  999|       0|nonexistent|\n",
      "|         10|telephone|  may|        mon|     293|       1|  999|       0|nonexistent|\n",
      "|         11|telephone|  may|        mon|     146|       1|  999|       0|nonexistent|\n",
      "|         12|telephone|  may|        mon|     174|       1|  999|       0|nonexistent|\n",
      "|         13|telephone|  may|        mon|     312|       1|  999|       0|nonexistent|\n",
      "|         14|telephone|  may|        mon|     440|       1|  999|       0|nonexistent|\n",
      "|         15|telephone|  may|        mon|     353|       1|  999|       0|nonexistent|\n",
      "|         16|telephone|  may|        mon|     195|       1|  999|       0|nonexistent|\n",
      "|         17|telephone|  may|        mon|     262|       1|  999|       0|nonexistent|\n",
      "|         18|telephone|  may|        mon|     342|       1|  999|       0|nonexistent|\n",
      "|         19|telephone|  may|        mon|     181|       1|  999|       0|nonexistent|\n",
      "|         20|telephone|  may|        mon|     172|       1|  999|       0|nonexistent|\n",
      "+-----------+---------+-----+-----------+--------+--------+-----+--------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "campaign_details.write.mode(\"overwrite\").saveAsTable('campaign_details')\n",
    "spark.sql(\"select * from campaign_details\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---+\n",
      "|Customer_id|  y|\n",
      "+-----------+---+\n",
      "|          1| no|\n",
      "|          2| no|\n",
      "|          3| no|\n",
      "|          4| no|\n",
      "|          5| no|\n",
      "|          6| no|\n",
      "|          7| no|\n",
      "|          8| no|\n",
      "|          9| no|\n",
      "|         10| no|\n",
      "|         11| no|\n",
      "|         12| no|\n",
      "|         13| no|\n",
      "|         14| no|\n",
      "|         15| no|\n",
      "|         16| no|\n",
      "|         17| no|\n",
      "|         18| no|\n",
      "|         19| no|\n",
      "|         20| no|\n",
      "+-----------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response_data.write.mode(\"overwrite\").saveAsTable('response_data')\n",
    "spark.sql(\"select * from response_data\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+--------------+-------------+---------+-----------+\n",
      "|Customer_id|emp.var.rate|cons.price.idx|cons.conf.idx|euribor3m|nr.employed|\n",
      "+-----------+------------+--------------+-------------+---------+-----------+\n",
      "|          1|         1.1|        93.994|        -36.4|    4.857|     5191.0|\n",
      "|          2|         1.1|        93.994|        -36.4|    4.857|     5191.0|\n",
      "|          3|         1.1|        93.994|        -36.4|    4.857|     5191.0|\n",
      "|          4|         1.1|        93.994|        -36.4|    4.857|     5191.0|\n",
      "|          5|         1.1|        93.994|        -36.4|    4.857|     5191.0|\n",
      "|          6|         1.1|        93.994|        -36.4|    4.857|     5191.0|\n",
      "|          7|         1.1|        93.994|        -36.4|    4.857|     5191.0|\n",
      "|          8|         1.1|        93.994|        -36.4|    4.857|     5191.0|\n",
      "|          9|         1.1|        93.994|        -36.4|    4.857|     5191.0|\n",
      "|         10|         1.1|        93.994|        -36.4|    4.857|     5191.0|\n",
      "|         11|         1.1|        93.994|        -36.4|    4.857|     5191.0|\n",
      "|         12|         1.1|        93.994|        -36.4|    4.857|     5191.0|\n",
      "|         13|         1.1|        93.994|        -36.4|    4.857|     5191.0|\n",
      "|         14|         1.1|        93.994|        -36.4|    4.857|     5191.0|\n",
      "|         15|         1.1|        93.994|        -36.4|    4.857|     5191.0|\n",
      "|         16|         1.1|        93.994|        -36.4|    4.857|     5191.0|\n",
      "|         17|         1.1|        93.994|        -36.4|    4.857|     5191.0|\n",
      "|         18|         1.1|        93.994|        -36.4|    4.857|     5191.0|\n",
      "|         19|         1.1|        93.994|        -36.4|    4.857|     5191.0|\n",
      "|         20|         1.1|        93.994|        -36.4|    4.857|     5191.0|\n",
      "+-----------+------------+--------------+-------------+---------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "economic_data.write.mode(\"overwrite\").saveAsTable('economic_data')\n",
    "spark.sql(\"select * from economic_data\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+--------+-------------------+-------+-------+----+-----------+----------+---------+---------+-----+-----------+--------+--------+-----+--------+-----------+-------+\n",
      "|age|        job| marital|          education|default|housing|loan|Region_Code|State_Code|City_Code|  contact|month|day_of_week|duration|campaign|pdays|previous|   poutcome|Deposit|\n",
      "+---+-----------+--------+-------------------+-------+-------+----+-----------+----------+---------+---------+-----+-----------+--------+--------+-----+--------+-----------+-------+\n",
      "| 56|   services| married|        high.school|     no|     no| yes|          3|        S1|       C1|telephone|  may|        mon|     307|       1|  999|       0|nonexistent|     no|\n",
      "| 45|   services| married|           basic.9y|unknown|     no|  no|          3|        S1|       C1|telephone|  may|        mon|     198|       1|  999|       0|nonexistent|     no|\n",
      "| 59|     admin.| married|professional.course|     no|     no|  no|          4|        S2|       C2|telephone|  may|        mon|     139|       1|  999|       0|nonexistent|     no|\n",
      "| 41|blue-collar| married|            unknown|unknown|     no|  no|          3|        S3|       C3|telephone|  may|        mon|     217|       1|  999|       0|nonexistent|     no|\n",
      "| 24| technician|  single|professional.course|     no|    yes|  no|          3|        S3|       C3|telephone|  may|        mon|     380|       1|  999|       0|nonexistent|     no|\n",
      "| 25|   services|  single|        high.school|     no|    yes|  no|          4|        S2|       C2|telephone|  may|        mon|      50|       1|  999|       0|nonexistent|     no|\n",
      "| 41|blue-collar| married|            unknown|unknown|     no|  no|          4|        S2|       C2|telephone|  may|        mon|      55|       1|  999|       0|nonexistent|     no|\n",
      "| 25|   services|  single|        high.school|     no|    yes|  no|          4|        S2|       C2|telephone|  may|        mon|     222|       1|  999|       0|nonexistent|     no|\n",
      "| 29|blue-collar|  single|        high.school|     no|     no| yes|          4|        S2|       C2|telephone|  may|        mon|     137|       1|  999|       0|nonexistent|     no|\n",
      "| 57|  housemaid|divorced|           basic.4y|     no|    yes|  no|         Na|        S2|       C2|telephone|  may|        mon|     293|       1|  999|       0|nonexistent|     no|\n",
      "| 35|blue-collar| married|           basic.6y|     no|    yes|  no|          4|        S2|       C2|telephone|  may|        mon|     146|       1|  999|       0|nonexistent|     no|\n",
      "| 54|    retired| married|           basic.9y|unknown|    yes| yes|          4|        S2|       C2|telephone|  may|        mon|     174|       1|  999|       0|nonexistent|     no|\n",
      "| 35|blue-collar| married|           basic.6y|     no|    yes|  no|          3|        S4|       C4|telephone|  may|        mon|     312|       1|  999|       0|nonexistent|     no|\n",
      "| 46|blue-collar| married|           basic.6y|unknown|    yes| yes|          4|        S5|       C5|telephone|  may|        mon|     440|       1|  999|       0|nonexistent|     no|\n",
      "| 50|blue-collar| married|           basic.9y|     no|    yes| yes|          1|        S6|       C6|telephone|  may|        mon|     353|       1|  999|       0|nonexistent|     no|\n",
      "| 39| management|  single|           basic.9y|unknown|     no|  no|          1|        S6|       C6|telephone|  may|        mon|     195|       1|  999|       0|nonexistent|     no|\n",
      "| 55|blue-collar| married|           basic.4y|unknown|    yes|  no|          1|        S7|       C7|telephone|  may|        mon|     262|       1|  999|       0|nonexistent|     no|\n",
      "| 55|    retired|  single|        high.school|     no|    yes|  no|          4|        S8|       C8|telephone|  may|        mon|     342|       1|  999|       0|nonexistent|     no|\n",
      "| 41| technician|  single|        high.school|     no|    yes|  no|          4|        S2|       C9|telephone|  may|        mon|     181|       1|  999|       0|nonexistent|     no|\n",
      "| 37|     admin.| married|        high.school|     no|    yes|  no|          4|        S2|       C9|telephone|  may|        mon|     172|       1|  999|       0|nonexistent|     no|\n",
      "+---+-----------+--------+-------------------+-------+-------+----+-----------+----------+---------+---------+-----+-----------+--------+--------+-----+--------+-----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer_final.write.mode(\"overwrite\").saveAsTable('customer_final')\n",
    "spark.sql(\"select * from customer_final\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---+---+-------+---------+-------+-------+----+-----------+----------+---------+-------+-----+-----------+--------+--------+-----+--------+--------+-------+\n",
      "|Customer_id|age|job|marital|education|default|housing|loan|Region_Code|State_Code|City_Code|contact|month|day_of_week|duration|campaign|pdays|previous|poutcome|Deposit|\n",
      "+-----------+---+---+-------+---------+-------+-------+----+-----------+----------+---------+-------+-----+-----------+--------+--------+-----+--------+--------+-------+\n",
      "|          0|  0|  0|      0|        0|      0|      0|   0|          0|         0|        0|      0|    0|          0|       0|       0|    0|       0|       0|      0|\n",
      "+-----------+---+---+-------+---------+-------+-------+----+-----------+----------+---------+-------+-----+-----------+--------+--------+-----+--------+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnull, when, count, col\n",
    "final_df.select([count(when(isnull(c), c)).alias(c) for c in final_df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num = ['Customer_id','age','job','marital','education','default','housing','loan','Region_Code','State_Code','City_Code','contact','month','day_of_week','duration','campaign','pdays','previous','poutcome','Deposit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+\n",
      "|     Column|DistinctCount|\n",
      "+-----------+-------------+\n",
      "|Customer_id|        37084|\n",
      "|        age|           77|\n",
      "|        job|           12|\n",
      "|    marital|            4|\n",
      "|  education|            8|\n",
      "|    default|            3|\n",
      "|    housing|            3|\n",
      "|       loan|            3|\n",
      "|Region_Code|            5|\n",
      "| State_Code|           49|\n",
      "|  City_Code|          531|\n",
      "|    contact|            2|\n",
      "|      month|           10|\n",
      "|day_of_week|            5|\n",
      "|   duration|         1509|\n",
      "|   campaign|           42|\n",
      "|      pdays|           27|\n",
      "|   previous|            8|\n",
      "|   poutcome|            3|\n",
      "|    Deposit|            2|\n",
      "+-----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "def get_distinct_counts(spark, df1, df_num):\n",
    "    schema = StructType([ \\\n",
    "        StructField(\"Column\",StringType(),True), \\\n",
    "        StructField(\"DistinctCount\",StringType(),True)\n",
    "      ])\n",
    "    emptyRDD = spark.sparkContext.emptyRDD()\n",
    "    resultdf = spark.createDataFrame(emptyRDD, schema=schema)\n",
    "     \n",
    "    for x in df_num:\n",
    "        df_distinct_count = df1.select(F.col(x)).distinct().count()\n",
    "        df_distinct = spark.createDataFrame([[x, str(df_distinct_count)]],schema=schema)\n",
    "        resultdf = resultdf.union(df_distinct)\n",
    "    return (resultdf)\n",
    "result1 = get_distinct_counts(spark,final_df,df_num)\n",
    "result1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution for - age\n",
      "+---+-----+\n",
      "|age|count|\n",
      "+---+-----+\n",
      "| 31| 1761|\n",
      "| 33| 1656|\n",
      "| 32| 1644|\n",
      "| 36| 1627|\n",
      "| 35| 1584|\n",
      "| 34| 1568|\n",
      "| 30| 1536|\n",
      "| 37| 1340|\n",
      "| 29| 1306|\n",
      "| 39| 1281|\n",
      "| 38| 1267|\n",
      "| 41| 1152|\n",
      "| 42| 1038|\n",
      "| 40| 1037|\n",
      "| 45|  987|\n",
      "| 46|  944|\n",
      "| 43|  935|\n",
      "| 44|  907|\n",
      "| 28|  896|\n",
      "| 48|  875|\n",
      "+---+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "Distribution for - job\n",
      "+-------------+-----+\n",
      "|          job|count|\n",
      "+-------------+-----+\n",
      "|       admin.| 9420|\n",
      "|  blue-collar| 8314|\n",
      "|   technician| 6096|\n",
      "|     services| 3547|\n",
      "|   management| 2637|\n",
      "|      retired| 1541|\n",
      "| entrepreneur| 1309|\n",
      "|self-employed| 1276|\n",
      "|    housemaid|  946|\n",
      "|   unemployed|  925|\n",
      "|      student|  767|\n",
      "|      unknown|  306|\n",
      "+-------------+-----+\n",
      "\n",
      "Distribution for - marital\n",
      "+--------+-----+\n",
      "| marital|count|\n",
      "+--------+-----+\n",
      "| married|22479|\n",
      "|  single|10407|\n",
      "|divorced| 4126|\n",
      "| unknown|   72|\n",
      "+--------+-----+\n",
      "\n",
      "Distribution for - education\n",
      "+-------------------+-----+\n",
      "|          education|count|\n",
      "+-------------------+-----+\n",
      "|  university.degree|10971|\n",
      "|        high.school| 8542|\n",
      "|           basic.9y| 5421|\n",
      "|professional.course| 4746|\n",
      "|           basic.4y| 3765|\n",
      "|           basic.6y| 2074|\n",
      "|            unknown| 1549|\n",
      "|         illiterate|   16|\n",
      "+-------------------+-----+\n",
      "\n",
      "Distribution for - default\n",
      "+-------+-----+\n",
      "|default|count|\n",
      "+-------+-----+\n",
      "|     no|29382|\n",
      "|unknown| 7700|\n",
      "|    yes|    2|\n",
      "+-------+-----+\n",
      "\n",
      "Distribution for - housing\n",
      "+-------+-----+\n",
      "|housing|count|\n",
      "+-------+-----+\n",
      "|    yes|19433|\n",
      "|     no|16769|\n",
      "|unknown|  882|\n",
      "+-------+-----+\n",
      "\n",
      "Distribution for - loan\n",
      "+-------+-----+\n",
      "|   loan|count|\n",
      "+-------+-----+\n",
      "|     no|30561|\n",
      "|    yes| 5641|\n",
      "|unknown|  882|\n",
      "+-------+-----+\n",
      "\n",
      "Distribution for - Region_Code\n",
      "+-----------+-----+\n",
      "|Region_Code|count|\n",
      "+-----------+-----+\n",
      "|          4|11884|\n",
      "|          2|10558|\n",
      "|          1| 8590|\n",
      "|          3| 5992|\n",
      "|         Na|   60|\n",
      "+-----------+-----+\n",
      "\n",
      "Distribution for - State_Code\n",
      "+----------+-----+\n",
      "|State_Code|count|\n",
      "+----------+-----+\n",
      "|        S2| 7427|\n",
      "|       S16| 4212|\n",
      "|        S6| 3614|\n",
      "|       S10| 2180|\n",
      "|        S5| 1881|\n",
      "|       S11| 1812|\n",
      "|       S25| 1732|\n",
      "|        S3| 1410|\n",
      "|       S13|  959|\n",
      "|        S4|  920|\n",
      "|       S17|  844|\n",
      "|       S18|  812|\n",
      "|       S33|  692|\n",
      "|       S23|  681|\n",
      "|       S19|  658|\n",
      "|       S15|  562|\n",
      "|        S1|  520|\n",
      "|       S32|  491|\n",
      "|       S31|  479|\n",
      "|       S22|  460|\n",
      "+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "Distribution for - City_Code\n",
      "+---------+-----+\n",
      "|City_Code|count|\n",
      "+---------+-----+\n",
      "|      C21| 3422|\n",
      "|       C2| 2781|\n",
      "|      C11| 1996|\n",
      "|       C9| 1906|\n",
      "|       C5| 1590|\n",
      "|      C13| 1372|\n",
      "|      C23| 1156|\n",
      "|      C39|  830|\n",
      "|      C71|  638|\n",
      "|      C25|  612|\n",
      "|      C62|  573|\n",
      "|     C109|  469|\n",
      "|      C67|  424|\n",
      "|      C47|  349|\n",
      "|     C103|  320|\n",
      "|      C30|  303|\n",
      "|      C26|  303|\n",
      "|      C35|  254|\n",
      "|      C43|  235|\n",
      "|      C53|  221|\n",
      "+---------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "Distribution for - contact\n",
      "+---------+-----+\n",
      "|  contact|count|\n",
      "+---------+-----+\n",
      "| cellular|23522|\n",
      "|telephone|13562|\n",
      "+---------+-----+\n",
      "\n",
      "Distribution for - month\n",
      "+-----+-----+\n",
      "|month|count|\n",
      "+-----+-----+\n",
      "|  may|12420|\n",
      "|  jul| 6430|\n",
      "|  aug| 5562|\n",
      "|  jun| 4786|\n",
      "|  nov| 3705|\n",
      "|  apr| 2388|\n",
      "|  oct|  630|\n",
      "|  sep|  510|\n",
      "|  mar|  487|\n",
      "|  dec|  166|\n",
      "+-----+-----+\n",
      "\n",
      "Distribution for - day_of_week\n",
      "+-----------+-----+\n",
      "|day_of_week|count|\n",
      "+-----------+-----+\n",
      "|        thu| 7778|\n",
      "|        mon| 7671|\n",
      "|        wed| 7341|\n",
      "|        tue| 7262|\n",
      "|        fri| 7032|\n",
      "+-----------+-----+\n",
      "\n",
      "Distribution for - duration\n",
      "+--------+-----+\n",
      "|duration|count|\n",
      "+--------+-----+\n",
      "|      72|  155|\n",
      "|      73|  152|\n",
      "|      85|  151|\n",
      "|     124|  151|\n",
      "|      90|  149|\n",
      "|      87|  148|\n",
      "|     136|  147|\n",
      "|     109|  146|\n",
      "|      82|  145|\n",
      "|     104|  145|\n",
      "|     111|  144|\n",
      "|     106|  140|\n",
      "|     135|  140|\n",
      "|     126|  140|\n",
      "|      96|  139|\n",
      "|      97|  139|\n",
      "|     122|  139|\n",
      "|     114|  139|\n",
      "|      76|  139|\n",
      "|     125|  138|\n",
      "+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "Distribution for - campaign\n",
      "+--------+-----+\n",
      "|campaign|count|\n",
      "+--------+-----+\n",
      "|       1|15883|\n",
      "|       2| 9532|\n",
      "|       3| 4777|\n",
      "|       4| 2389|\n",
      "|       5| 1441|\n",
      "|       6|  873|\n",
      "|       7|  580|\n",
      "|       8|  360|\n",
      "|       9|  260|\n",
      "|      10|  196|\n",
      "|      11|  165|\n",
      "|      12|  118|\n",
      "|      13|   88|\n",
      "|      14|   62|\n",
      "|      17|   49|\n",
      "|      16|   45|\n",
      "|      15|   41|\n",
      "|      18|   32|\n",
      "|      20|   28|\n",
      "|      19|   25|\n",
      "+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_num_2=['age','job','marital','education','default','housing','loan','Region_Code','State_Code','City_Code','contact','month','day_of_week','duration','campaign']\n",
    "\n",
    "def get_distribution_counts(spark, df1, df_num):\n",
    "    result = []\n",
    "    for i in df_num:\n",
    "        result.append(df1.groupby(F.col(i)).count().sort(F.col(\"count\").desc()))\n",
    "    return result\n",
    "result = get_distribution_counts(spark, final_df, df_num_2)\n",
    "for i in result:\n",
    "    print(\"Distribution for - \" + i.columns[0] )\n",
    "    i.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|          education|\n",
      "+-------------------+\n",
      "|        high.school|\n",
      "|            unknown|\n",
      "|           basic.6y|\n",
      "|professional.course|\n",
      "|  university.degree|\n",
      "|         illiterate|\n",
      "|           basic.4y|\n",
      "|           basic.9y|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df.select(\"education\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "| marital|\n",
      "+--------+\n",
      "| unknown|\n",
      "|divorced|\n",
      "| married|\n",
      "|  single|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df.select(\"marital\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|          job|\n",
      "+-------------+\n",
      "|   management|\n",
      "|      retired|\n",
      "|      unknown|\n",
      "|self-employed|\n",
      "|      student|\n",
      "|  blue-collar|\n",
      "| entrepreneur|\n",
      "|       admin.|\n",
      "|   technician|\n",
      "|     services|\n",
      "|    housemaid|\n",
      "|   unemployed|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df.select(\"job\").distinct().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- State_Code: string (nullable = true)\n",
      " |-- State_Name: string (nullable = true)\n",
      " |-- Region_Code: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "state_df=spark.read.load(\"State_Master.csv\", format=\"csv\", inferSchema=\"true\", header=\"true\")\n",
    "state_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Region_Name: string (nullable = true)\n",
      " |-- Region_Code: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "region_df=spark.read.load(\"Region_code_master.csv\", format=\"csv\", inferSchema=\"true\", header=\"true\")\n",
    "region_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City_Code: string (nullable = true)\n",
      " |-- City_Name: string (nullable = true)\n",
      " |-- State_Code: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "city_df=spark.read.load(\"City_Master.csv\", format=\"csv\", inferSchema=\"true\", header=\"true\")\n",
    "city_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Region_Code: integer (nullable = true)\n",
      " |-- State_Code: string (nullable = true)\n",
      " |-- State_Name: string (nullable = true)\n",
      " |-- Region_Name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demographics=state_df.join(region_df, on='Region_Code')\n",
    "demographics.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- State_Code: string (nullable = true)\n",
      " |-- Region_Code: integer (nullable = true)\n",
      " |-- State_Name: string (nullable = true)\n",
      " |-- Region_Name: string (nullable = true)\n",
      " |-- City_Code: string (nullable = true)\n",
      " |-- City_Name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demographics=demographics.join(city_df, on='State_Code')\n",
    "demographics.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+----------+-----------+---------+---------------+\n",
      "|State_Code|Region_Code|State_Name|Region_Name|City_Code|      City_Name|\n",
      "+----------+-----------+----------+-----------+---------+---------------+\n",
      "|        S1|          3|  Kentucky|      South|     C460|      Owensboro|\n",
      "|        S1|          3|  Kentucky|      South|     C431|     Georgetown|\n",
      "|        S1|          3|  Kentucky|      South|     C257|  Bowling Green|\n",
      "|        S1|          3|  Kentucky|      South|     C209|         Murray|\n",
      "|        S1|          3|  Kentucky|      South|     C160|       Florence|\n",
      "|        S1|          3|  Kentucky|      South|     C103|       Richmond|\n",
      "|        S1|          3|  Kentucky|      South|       C1|      Henderson|\n",
      "|        S2|          4|California|       West|     C530|           Lodi|\n",
      "|        S2|          4|California|       West|     C528|San Luis Obispo|\n",
      "|        S2|          4|California|       West|     C527|   San Clemente|\n",
      "+----------+-----------+----------+-----------+---------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demographics.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|Region_Name|\n",
      "+-----------+\n",
      "|      South|\n",
      "|    Central|\n",
      "|       East|\n",
      "|       West|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demographics.select(\"Region_Name\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|          State_Name|\n",
      "+--------------------+\n",
      "|                Utah|\n",
      "|           Minnesota|\n",
      "|                Ohio|\n",
      "|              Oregon|\n",
      "|            Arkansas|\n",
      "|               Texas|\n",
      "|        North Dakota|\n",
      "|        Pennsylvania|\n",
      "|         Connecticut|\n",
      "|            Nebraska|\n",
      "|              Nevada|\n",
      "|          Washington|\n",
      "|            Illinois|\n",
      "|            Oklahoma|\n",
      "|District of Columbia|\n",
      "|            Delaware|\n",
      "|          New Mexico|\n",
      "|            Missouri|\n",
      "|        Rhode Island|\n",
      "|             Georgia|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demographics.select(\"State_Name\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|      City_Name|\n",
      "+---------------+\n",
      "|          Tyler|\n",
      "|  Bowling Green|\n",
      "|          Pasco|\n",
      "|        Edmonds|\n",
      "|          Tempe|\n",
      "|    Springfield|\n",
      "|       Palatine|\n",
      "|         Auburn|\n",
      "|       Thornton|\n",
      "|North Las Vegas|\n",
      "|     Georgetown|\n",
      "|  Lake Elsinore|\n",
      "|         Wilson|\n",
      "|      Bethlehem|\n",
      "|        Phoenix|\n",
      "|     Plainfield|\n",
      "|      Hollywood|\n",
      "|       Woodland|\n",
      "|         Monroe|\n",
      "| Pembroke Pines|\n",
      "+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demographics.select(\"City_Name\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import min, max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+\n",
      "|min(age)|max(age)|\n",
      "+--------+--------+\n",
      "|17      |98      |\n",
      "+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df.select(min(\"age\"),max(\"age\")).show(final_df.count(),False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+\n",
      "|min(campaign)|max(campaign)|\n",
      "+-------------+-------------+\n",
      "|1            |56           |\n",
      "+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df.select(min(\"campaign\"),max(\"campaign\")).show(final_df.count(),False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(correlation=-0.07830000712402792)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.stat import Correlation\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.functions import corr\n",
    "final_df.agg(corr(\"previous\", \"campaign\").alias('correlation')).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|               age|\n",
      "+-------+------------------+\n",
      "|  count|             37084|\n",
      "|   mean|40.042713838852336|\n",
      "| stddev| 10.43296498543827|\n",
      "|    min|                17|\n",
      "|    max|                98|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df.select('age').describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|summary|           previous|\n",
      "+-------+-------------------+\n",
      "|  count|              37084|\n",
      "|   mean|0.17298565419048648|\n",
      "| stddev| 0.4956814561131696|\n",
      "|    min|                  0|\n",
      "|    max|                  7|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df.select('previous').describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|             pdays|\n",
      "+-------+------------------+\n",
      "|  count|             37084|\n",
      "|   mean| 962.5308488836156|\n",
      "| stddev|186.77306297861892|\n",
      "|    min|                 0|\n",
      "|    max|               999|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df.select('pdays').describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Customer_id: integer (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- Region_Code: string (nullable = true)\n",
      " |-- State_Code: string (nullable = true)\n",
      " |-- City_Code: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- day_of_week: string (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- campaign: integer (nullable = true)\n",
      " |-- pdays: integer (nullable = true)\n",
      " |-- previous: integer (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- Deposit: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- campaign: integer (nullable = true)\n",
      " |-- pdays: integer (nullable = true)\n",
      " |-- previous: integer (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- deposit: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df = final_df.select('age', 'job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'duration', 'campaign', 'pdays', 'previous', 'poutcome', 'deposit')\n",
    "cols = final_df.columns\n",
    "final_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# categoricalColumns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'poutcome']\n",
    "\n",
    "# stages = []\n",
    "\n",
    "# for categoricalCol in categoricalColumns:\n",
    "    \n",
    "#     stringIndexer = StringIndexer(inputCol = categoricalCol, outputCol = categoricalCol + 'Index')\n",
    "    \n",
    "#     #encoder = OneHotEncoder(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + 'classVec'])\n",
    "    \n",
    "#     columnTransformer = ColumnTransformer([('encoder', OneHotEncoder(),categoricalColumns )], remainder='passthrough')\n",
    "    \n",
    "    \n",
    "#     stages += [stringIndexer,columnTransformer]\n",
    "    \n",
    "# label_stringIdx = StringIndexer(inputCol = 'deposit', outputCol = 'label')\n",
    "    \n",
    "# stages += [label_stringIdx]\n",
    "# numericCols = ['age', 'balance', 'duration', 'campaign', 'pdays', 'previous']\n",
    "\n",
    "# assemblerInputs = [c + \"classVec\" for c in categoricalColumns] + numericCols\n",
    "\n",
    "# assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "\n",
    "# stages += [assembler]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.ml import Pipeline\n",
    "# pipeline = Pipeline(stages = stages)\n",
    "# pipelineModel = pipeline.fit(final_df)\n",
    "# final_df = pipelineModel.transform(final_df)\n",
    "# selectedCols = ['label', 'features'] + cols\n",
    "# final_df = final_df.select(selectedCols)\n",
    "# final_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------+-----+--------+--------+------------+--------------+------------+------------+---------+------------+-------------+------------+\n",
      "|age|duration|campaign|pdays|previous|jobindex|maritalindex|educationindex|defaultindex|housingindex|loanindex|contactindex|poutcomeindex|depositindex|\n",
      "+---+--------+--------+-----+--------+--------+------------+--------------+------------+------------+---------+------------+-------------+------------+\n",
      "| 56|     307|       1|  999|       0|     3.0|         0.0|           1.0|         0.0|         1.0|      1.0|         1.0|          0.0|         0.0|\n",
      "| 45|     198|       1|  999|       0|     3.0|         0.0|           2.0|         1.0|         1.0|      0.0|         1.0|          0.0|         0.0|\n",
      "| 59|     139|       1|  999|       0|     0.0|         0.0|           3.0|         0.0|         1.0|      0.0|         1.0|          0.0|         0.0|\n",
      "| 41|     217|       1|  999|       0|     1.0|         0.0|           6.0|         1.0|         1.0|      0.0|         1.0|          0.0|         0.0|\n",
      "| 24|     380|       1|  999|       0|     2.0|         1.0|           3.0|         0.0|         0.0|      0.0|         1.0|          0.0|         0.0|\n",
      "| 25|      50|       1|  999|       0|     3.0|         1.0|           1.0|         0.0|         0.0|      0.0|         1.0|          0.0|         0.0|\n",
      "| 41|      55|       1|  999|       0|     1.0|         0.0|           6.0|         1.0|         1.0|      0.0|         1.0|          0.0|         0.0|\n",
      "| 25|     222|       1|  999|       0|     3.0|         1.0|           1.0|         0.0|         0.0|      0.0|         1.0|          0.0|         0.0|\n",
      "| 29|     137|       1|  999|       0|     1.0|         1.0|           1.0|         0.0|         1.0|      1.0|         1.0|          0.0|         0.0|\n",
      "| 57|     293|       1|  999|       0|     8.0|         2.0|           4.0|         0.0|         0.0|      0.0|         1.0|          0.0|         0.0|\n",
      "| 35|     146|       1|  999|       0|     1.0|         0.0|           5.0|         0.0|         0.0|      0.0|         1.0|          0.0|         0.0|\n",
      "| 54|     174|       1|  999|       0|     5.0|         0.0|           2.0|         1.0|         0.0|      1.0|         1.0|          0.0|         0.0|\n",
      "| 35|     312|       1|  999|       0|     1.0|         0.0|           5.0|         0.0|         0.0|      0.0|         1.0|          0.0|         0.0|\n",
      "| 46|     440|       1|  999|       0|     1.0|         0.0|           5.0|         1.0|         0.0|      1.0|         1.0|          0.0|         0.0|\n",
      "| 50|     353|       1|  999|       0|     1.0|         0.0|           2.0|         0.0|         0.0|      1.0|         1.0|          0.0|         0.0|\n",
      "| 39|     195|       1|  999|       0|     4.0|         1.0|           2.0|         1.0|         1.0|      0.0|         1.0|          0.0|         0.0|\n",
      "| 55|     262|       1|  999|       0|     1.0|         0.0|           4.0|         1.0|         0.0|      0.0|         1.0|          0.0|         0.0|\n",
      "| 55|     342|       1|  999|       0|     5.0|         1.0|           1.0|         0.0|         0.0|      0.0|         1.0|          0.0|         0.0|\n",
      "| 41|     181|       1|  999|       0|     2.0|         1.0|           1.0|         0.0|         0.0|      0.0|         1.0|          0.0|         0.0|\n",
      "| 37|     172|       1|  999|       0|     0.0|         0.0|           1.0|         0.0|         0.0|      0.0|         1.0|          0.0|         0.0|\n",
      "+---+--------+--------+-----+--------+--------+------------+--------------+------------+------------+---------+------------+-------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "for col,type in final_df.dtypes:\n",
    "    if type=='string':\n",
    "        indexer = StringIndexer(inputCol=col, outputCol=col+\"index\")\n",
    "        final_df = indexer.fit(final_df).transform(final_df)\n",
    "        final_df=final_df.drop(col)\n",
    "final_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- campaign: integer (nullable = true)\n",
      " |-- pdays: integer (nullable = true)\n",
      " |-- previous: integer (nullable = true)\n",
      " |-- jobindex: double (nullable = true)\n",
      " |-- maritalindex: double (nullable = true)\n",
      " |-- educationindex: double (nullable = true)\n",
      " |-- defaultindex: double (nullable = true)\n",
      " |-- housingindex: double (nullable = true)\n",
      " |-- loanindex: double (nullable = true)\n",
      " |-- contactindex: double (nullable = true)\n",
      " |-- poutcomeindex: double (nullable = true)\n",
      " |-- depositindex: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "'Field \"features\" does not exist.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o1092.fit.\n: java.lang.IllegalArgumentException: Field \"features\" does not exist.\n\tat org.apache.spark.sql.types.StructType$$anonfun$apply$1.apply(StructType.scala:266)\n\tat org.apache.spark.sql.types.StructType$$anonfun$apply$1.apply(StructType.scala:266)\n\tat scala.collection.MapLike$class.getOrElse(MapLike.scala:128)\n\tat scala.collection.AbstractMap.getOrElse(Map.scala:59)\n\tat org.apache.spark.sql.types.StructType.apply(StructType.scala:265)\n\tat org.apache.spark.ml.util.SchemaUtils$.checkColumnType(SchemaUtils.scala:40)\n\tat org.apache.spark.ml.PredictorParams$class.validateAndTransformSchema(Predictor.scala:51)\n\tat org.apache.spark.ml.classification.Classifier.org$apache$spark$ml$classification$ClassifierParams$$super$validateAndTransformSchema(Classifier.scala:58)\n\tat org.apache.spark.ml.classification.ClassifierParams$class.validateAndTransformSchema(Classifier.scala:42)\n\tat org.apache.spark.ml.classification.ProbabilisticClassifier.org$apache$spark$ml$classification$ProbabilisticClassifierParams$$super$validateAndTransformSchema(ProbabilisticClassifier.scala:53)\n\tat org.apache.spark.ml.classification.ProbabilisticClassifierParams$class.validateAndTransformSchema(ProbabilisticClassifier.scala:37)\n\tat org.apache.spark.ml.classification.LogisticRegression.org$apache$spark$ml$classification$LogisticRegressionParams$$super$validateAndTransformSchema(LogisticRegression.scala:278)\n\tat org.apache.spark.ml.classification.LogisticRegressionParams$class.validateAndTransformSchema(LogisticRegression.scala:265)\n\tat org.apache.spark.ml.classification.LogisticRegression.validateAndTransformSchema(LogisticRegression.scala:278)\n\tat org.apache.spark.ml.Predictor.transformSchema(Predictor.scala:144)\n\tat org.apache.spark.ml.PipelineStage.transformSchema(Pipeline.scala:74)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:100)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:82)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-62de2ffbaaf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mlrModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Print the coefficients and intercept for logistic regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \"\"\"\n\u001b[1;32m    261\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mQueryExecutionException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'java.lang.IllegalArgumentException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mIllegalArgumentException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: 'Field \"features\" does not exist.'"
     ]
    }
   ],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"age\",\"duration\",\"campaign\",\"pdays\",\"previous\",\"jobindex\",\"maritalindex\",\"educationindex\",\"defaultindex\",\"housingindex\",\"loanindex\",\"contactindex\",\"poutcomeindex\"],\n",
    "    outputCol=\"features\")\n",
    "\n",
    "(training, test) = final_df.randomSplit([0.7, 0.3])\n",
    "\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8,featuresCol=\"features\",labelCol=\"depositindex\")\n",
    "\n",
    "\n",
    "lrModel = lr.fit(training)\n",
    "\n",
    "# Print the coefficients and intercept for logistic regression\n",
    "print(\"Coefficients: %s\" % str(lrModel.coefficients))\n",
    "print(\"Intercept: %s\" % str(lrModel.intercept))\n",
    "\n",
    "# Summarize the model over the training set and print out some metrics\n",
    "trainingSummary = lrModel.summary\n",
    "print(\"numIterations: %d\" % trainingSummary.totalIterations)\n",
    "print(\"objectiveHistory: %s\" % str(trainingSummary.objectiveHistory))\n",
    "trainingSummary.residuals.show()\n",
    "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "print(\"r2: %f\" % trainingSummary.r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
